[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - Can We Predict That?",
    "section": "",
    "text": "This model sorts through the data given, and then predicts based off certain parameters if the house was built before or after 1980. I find it very interesting how much information you get based off whether the garage was attached or not. ALmost all of the houses with a detached garage were built before the year 1980. Same for the if they were one story. If they only have one story, they likely were built before 1980 because the house gets reburbished to be updated and not rebuilt.\n\n\nRead and format project data\n# Include and execute your code here\ndwellings_ml = pd.read_csv('https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv')\n\n\n\n\nShow the code\ndwellings_ml.head()\n\n\n\n\n\n\n\n\n\nparcel\nabstrprd\nlivearea\nfinbsmnt\nbasement\nyrbuilt\ntotunits\nstories\nnocars\nnumbdrm\n...\narcstyle_THREE-STORY\narcstyle_TRI-LEVEL\narcstyle_TRI-LEVEL WITH BASEMENT\narcstyle_TWO AND HALF-STORY\narcstyle_TWO-STORY\nqualified_Q\nqualified_U\nstatus_I\nstatus_V\nbefore1980\n\n\n\n\n0\n00102-08-065-065\n1130\n1346\n0\n0\n2004\n1\n2\n2\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n1\n00102-08-073-073\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n2\n00102-08-078-078\n1130\n1346\n0\n0\n2005\n1\n2\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n3\n00102-08-081-081\n1130\n1146\n0\n0\n2005\n1\n1\n0\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n4\n00102-08-086-086\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n\n\n\n5 rows × 51 columns\n\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - Can We Predict That?",
    "section": "",
    "text": "This model sorts through the data given, and then predicts based off certain parameters if the house was built before or after 1980. I find it very interesting how much information you get based off whether the garage was attached or not. ALmost all of the houses with a detached garage were built before the year 1980. Same for the if they were one story. If they only have one story, they likely were built before 1980 because the house gets reburbished to be updated and not rebuilt.\n\n\nRead and format project data\n# Include and execute your code here\ndwellings_ml = pd.read_csv('https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv')\n\n\n\n\nShow the code\ndwellings_ml.head()\n\n\n\n\n\n\n\n\n\nparcel\nabstrprd\nlivearea\nfinbsmnt\nbasement\nyrbuilt\ntotunits\nstories\nnocars\nnumbdrm\n...\narcstyle_THREE-STORY\narcstyle_TRI-LEVEL\narcstyle_TRI-LEVEL WITH BASEMENT\narcstyle_TWO AND HALF-STORY\narcstyle_TWO-STORY\nqualified_Q\nqualified_U\nstatus_I\nstatus_V\nbefore1980\n\n\n\n\n0\n00102-08-065-065\n1130\n1346\n0\n0\n2004\n1\n2\n2\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n1\n00102-08-073-073\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n2\n00102-08-078-078\n1130\n1346\n0\n0\n2005\n1\n2\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n3\n00102-08-081-081\n1130\n1146\n0\n0\n2005\n1\n1\n0\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n4\n00102-08-086-086\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n\n\n\n5 rows × 51 columns\n\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - Can We Predict That?",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCreate 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.\nChart one shows the inflation in house price over time. The trend line is on a slow but steady positive trajectory. While it is not the most clear cut way of deterining whether it is after or before 1980, the computer can start to infer that the higher the sale price, the newer the house.\n\n\nRead and format data\n# Include and execute your code here\ndf = dwellings_ml\nfig = px.scatter(df,\n    x = 'yrbuilt', \n    y = 'sprice',\n    color = ('before1980'),\n    trendline = \"ols\",\n    title = 'The Price of New Houses Over Time')\n\nfig.update_layout(\n    plot_bgcolor = 'white',\n    xaxis_title = 'Year Built',\n    yaxis_title = 'Selling Price')\n\nfig.show()\n\n\n                                                \n\n\nChart two shows the distribution of houses that have attached garages. If a house does not have an attached garage, the model will be able to know that the house is very likely to be made before 1980.\n::: {#cell-Q1 chart .cell execution_count=5}\n\nplot example\n# Include and execute your code here\n#make a chart with gartype\ndf = dwellings_ml\nfig = px.histogram(df,\n    x = 'gartype_Att',\n    color = 'before1980',\n    title = 'The distribution of houses that have attached garages, seperated by pre and post 1980'    \n)\nfig.show()\n\n\n                                                \nMy useless chart\n\n:::\nThe chart shows the distribution of houses with one, two, three, and four floors. Based off this data we learn that the model will infer that if the house has multiple one floor it likely was built before 1980.\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=6}\n\ntable example\n# Include and execute your code here\ndf = dwellings_ml\nfig = px.histogram(df,\n    x = 'stories',\n    color = 'before1980',\n    title = 'The distribution of stories belonging to a house, seperated by pre and post 1980'   \n)\nfig.show()\n\n\n                                                \n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - Can We Predict That?",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.\ntype your results and analysis here At a .9 test size the model was accurate 87% of the time. It would be more accurate had we not over trained it. At a .1 test size it was accurate 92% of the time. With a .397 test size, it was 91% accurate. I settled on a .34 test size because it gave me the .92 but wasn’t too big of a sample split.\n\n\nRead and format data\n# Include and execute your code here\nX_pred = dwellings_ml.drop(dwellings_ml.filter(regex = 'before1980|yrbuilt').columns, axis = 1)\nx_pred_cat = pd.get_dummies(X_pred, drop_first = True)\ny_pred = dwellings_ml.filter(regex = \"before1980\")\n\nX_train, X_test, y_train, y_test = train_test_split(x_pred_cat, y_pred, test_size = .34, random_state = 76)\n\ny_test.head(10)\n\n\n\n\n\n\n\n\n\nbefore1980\n\n\n\n\n16075\n0\n\n\n10563\n0\n\n\n14087\n1\n\n\n9622\n0\n\n\n2172\n1\n\n\n9343\n0\n\n\n15953\n1\n\n\n755\n0\n\n\n13816\n1\n\n\n5612\n0\n\n\n\n\n\n\n\n\n\nplot example\n# Include and execute your code here\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_probs = clf.predict_proba(X_test)\nprint(metrics.classification_report(y_pred, y_test))\n\n\n              precision    recall  f1-score   support\n\n           0       0.89      0.88      0.88      2912\n           1       0.93      0.93      0.93      4879\n\n    accuracy                           0.91      7791\n   macro avg       0.91      0.91      0.91      7791\nweighted avg       0.91      0.91      0.91      7791",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - Can We Predict That?",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.\nMajority of the models accuraccy relies on ‘arcstyle ONE-STORY’, ‘gartype Att’, ‘quality C’, and ‘livearea’. Other categories were not nearly as helpful as those four. Quality C is if the house recieved a grade C on a letter scale. Livearea is the amount of liveable space the house has. gartype Att is if the garage is attached or not. Arcstyle ONE-STORY is if the srchitecture style of the house is one story or not.\n\n\nRead and format data\n# Include and execute your code here\ndf_features = pd.DataFrame(\n    {'f_names': X_train.columns, \n    'f_values': clf.feature_importances_}).sort_values('f_values', ascending = False)\n\nchart = px.bar(df_features.head(10),\n    x='f_values', \n    y='f_names'\n)\n\nchart.update_layout(yaxis={'categoryorder':'total ascending'})",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-4",
    "href": "Projects/project4.html#questiontask-4",
    "title": "Client Report - Can We Predict That?",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\nThe quality of this classification model has a recall value of .88 for being false and .93 for true. It also has a precision value of .89 for false .93 value for true. Recall is the rate of having it say it was built before 1980 when it actually wasn’t. Precision is the rate of having it say it isn’t built before 1980 when it really was.",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n::: {#cell-project data .cell execution_count=2}\n\nRead and format project data\n# Include and execute your code here\nurl = 'https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json'\n\ndelays = pd.read_json(url)\ndelays.head()\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500+\n-999\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\n\nJanuary\n2005.0\n12381\n414\n1058\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197\n2255\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572\n680\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552\n\n\n\n\n\n\n:::\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n::: {#cell-project data .cell execution_count=2}\n\nRead and format project data\n# Include and execute your code here\nurl = 'https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json'\n\ndelays = pd.read_json(url)\ndelays.head()\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500+\n-999\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\n\nJanuary\n2005.0\n12381\n414\n1058\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197\n2255\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572\n680\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552\n\n\n\n\n\n\n:::\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\ntype your results and analysis here\n\n\nShow the code\n#February is mispelled in the data\n#| label: Q1\n#| code-summary: Read and format data\n# Include and execute your code here\ndelays.month.replace(['NaN', 'n/a'],np.nan,inplace = True)\ndelays.month.replace('Febuary', 'February', inplace = True)\ndelays.num_of_delays_late_aircraft.replace(-999, np.nan, inplace = True)\ndelays.num_of_delays_carrier.replace('1500+', 1500, inplace = True)\ndelays.airport_name.replace('', 'Washington, DC: Washington Dulles International', inplace = True)\n# delays[minutes_delayed_carrier].replace('NaN', delays[minutes_delayed_carrier].mean(), inplace = True)\n\ndelays['month'] = delays['month'].ffill()\ndelays_clean = delays\ndelays_clean.head()\n# delays.to_json\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928.0\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\nWashington, DC: Washington Dulles International\nJanuary\n2005.0\n12381\n414\n1058.0\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197\n2255.0\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572\n680.0\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\ndf = delays[['airport_code', \n'num_of_flights_total', \n'num_of_delays_total', \n'minutes_delayed_total']]\ndf = df.groupby('airport_code').sum()\ndf['prop_of_delays'] = df['num_of_delays_total'] / df['num_of_flights_total']\ndf['hours_delayed_total'] = df['minutes_delayed_total'] / 60\ndf = df.drop(columns = ['minutes_delayed_total'])\ndf.reset_index(inplace = True)\ndf.head()\n\n\n\n\n\n\n\n\n\nairport_code\nnum_of_flights_total\nnum_of_delays_total\nprop_of_delays\nhours_delayed_total\n\n\n\n\n0\nATL\n4430047\n902443\n0.203710\n899732.100000\n\n\n1\nDEN\n2513974\n468519\n0.186366\n419556.350000\n\n\n2\nIAD\n851571\n168467\n0.197831\n171391.300000\n\n\n3\nORD\n3597588\n830825\n0.230939\n939268.816667\n\n\n4\nSAN\n917862\n175132\n0.190804\n137937.466667\n\n\n\n\n\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=5}\n\nplot example\n# Include and execute your code here\n\nchart = px.box(delays,\n    x=\"airport_code\", \n    y=\"num_of_delays_total\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\ndelays.month.value_counts()\npd.crosstab(\n    delays_clean.month, \n    delays_clean.airport_code)\n\n\n\n\n\n\n\n\nairport_code\nATL\nDEN\nIAD\nORD\nSAN\nSFO\nSLC\n\n\nmonth\n\n\n\n\n\n\n\n\n\n\n\nApril\n11\n11\n11\n11\n11\n11\n11\n\n\nAugust\n11\n11\n11\n11\n11\n11\n11\n\n\nDecember\n10\n11\n11\n11\n11\n11\n11\n\n\nFebruary\n11\n11\n11\n11\n11\n11\n11\n\n\nJanuary\n12\n11\n11\n11\n11\n11\n11\n\n\nJuly\n11\n11\n11\n11\n11\n11\n11\n\n\nJune\n11\n11\n11\n11\n11\n11\n11\n\n\nMarch\n10\n11\n11\n11\n11\n11\n11\n\n\nMay\n11\n11\n11\n11\n11\n11\n11\n\n\nNovember\n11\n11\n11\n11\n11\n11\n11\n\n\nOctober\n12\n11\n11\n11\n11\n11\n11\n\n\nSeptember\n11\n11\n11\n11\n11\n11\n11\n\n\n\n\n\n\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\nShow the code\nimport plotly.graph_objects as go\n\n\ncolors = ['lightslategray'] * 12 \ncolors[8] = 'crimson'  \n\ndelays_chart = delays.groupby(\"month\").agg({\"num_of_delays_total\":'sum'}).reset_index()\n\ndelays[\"month\"] = delays[\"month\"].astype(\"category\")\ndelays[\"month\"] = delays[\"month\"].cat.reorder_categories([\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"])\n\n\n\n\nShow the code\n# Order BY month in delays_chart\n\nchart = px.bar(delays_chart,\n    x=\"month\", \n    y=\"num_of_delays_total\"\n)\n\nchart.update_traces(marker_opacity=1)\n\n\nchart.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations: 100% of delayed flights in the Weather category are due to weather, 30% of all delayed flights in the Late-Arriving category are due to weather.From April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%.\ntype your results and analysis here\n\n\nRead and format data\nweather = (delays.assign(\n    severe = delays.num_of_delays_weather, # no missing\n    nodla_nona = lambda x: (x.num_of_delays_late_aircraft\n        .replace(-999, np.nan)), #missing is -999\n    mild_late = lambda x: x.nodla_nona.fillna(x.nodla_nona.mean())*0.3,\n    mild = np.where(\n        delays.month.isin(['April', 'May', 'June', 'July', 'August']), \n            delays.num_of_delays_nas*0.4,\n            delays.num_of_delays_nas*0.65),\n    weather = lambda x: x.severe + x.mild_late + x.mild,\n    proportion_weather_delay = lambda x: x.weather / x.num_of_delays_total,\n    proportion_weather_total = lambda x:  x.weather / x.num_of_flights_total)\n    .filter(['airport_code','month','year', 'severe','mild', 'mild_late',\n    'weather', 'num_of_flights_total', 'num_of_delays_total',   'proportion_weather_total', 'proportion_weather_delay']))\nweather.head()\n#\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nsevere\nmild\nmild_late\nweather\nnum_of_flights_total\nnum_of_delays_total\nproportion_weather_total\nproportion_weather_delay\n\n\n\n\n0\nATL\nJanuary\n2005.0\n448\n2988.70\n332.731222\n3769.431222\n35048\n8355\n0.107551\n0.451159\n\n\n1\nDEN\nJanuary\n2005.0\n233\n607.75\n278.400000\n1119.150000\n12687\n3153\n0.088212\n0.354948\n\n\n2\nIAD\nJanuary\n2005.0\n61\n581.75\n317.400000\n960.150000\n12381\n2430\n0.077550\n0.395123\n\n\n3\nORD\nJanuary\n2005.0\n306\n3519.75\n676.500000\n4502.250000\n28194\n9178\n0.159688\n0.490548\n\n\n4\nSAN\nJanuary\n2005.0\n56\n414.70\n204.000000\n674.700000\n7283\n1952\n0.092640\n0.345645",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n# delays.groupby(\"month\").agg({\"num_of_delays_total\":'sum'}).reset_index()\n\nchart = px.box(weather,\n    x=\"airport_code\", \n    y=\"proportion_weather_total\"\n)\nchart.show()\n\n\n                                                \n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q5 chart .cell execution_count=11}\n\nplot example\n# Include and execute your code here\n\nchart = px.bar(weather,\n    x=\"airport_code\", \n    y=\"proportion_weather_delay\",\n    barmode = 'group'\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n\n\ntable example\n# Include and execute your code here\n# mydat = df.head(1000)\\\n#     .groupby('year')\\\n#     .sum()\\\n#     .reset_index()\\\n#     .tail(10)\\\n#     .filter([\"year\", \"AK\",\"AR\"])\n\n# display(mydat)",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "personal/experimenting.html",
    "href": "personal/experimenting.html",
    "title": "Your_Name Data Science Portfolio",
    "section": "",
    "text": "df = pd.read_csv(r\"C:\\Users\\caleb\\OneDrive\\Desktop\\personal\\Data Science expreiments\\archive\\csv_yearly_data_updated_08_23.csv\")\n\n\n#display the progress Antonio Brown\n\nchart = px.line(\n        df.query('name == \"Antonio Brown\"'),\n        x = \"season\",\n        y = \"receiving_yards\"\n)\n\nchart.show()\n\n                                                \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "note.html",
    "href": "note.html",
    "title": "Your_Name Data Science Portfolio",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport sqlite3\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - [What’s In a Name?]",
    "section": "",
    "text": "Pop culture will always have a distinct impact on the culture of naming people. We see this specifically with the name Jordan. Just as Michael Jordan ruled pop culture in the 80s and 90s, the name ‘Jordan’ also saw a similar spike in popularity. The name was versatile, being a name for girls, boys, even shoes. The popularity also followed the basketball star, seeing distinct dropoff following the retirement of the phenom. \n\n\nRead and format project data\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\ndf = pd.read_csv(url)\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - [What’s In a Name?]",
    "section": "",
    "text": "Pop culture will always have a distinct impact on the culture of naming people. We see this specifically with the name Jordan. Just as Michael Jordan ruled pop culture in the 80s and 90s, the name ‘Jordan’ also saw a similar spike in popularity. The name was versatile, being a name for girls, boys, even shoes. The popularity also followed the basketball star, seeing distinct dropoff following the retirement of the phenom. \n\n\nRead and format project data\nurl = \"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\"\ndf = pd.read_csv(url)\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Client Report - [What’s In a Name?]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\nThe name ‘Caleb’ started it’s rise in popularity in the early 1970s. Over the years it showed a consistent slow increase in usage till 1988 where the name started to skyrocket. It continues this gradual increase till 2002, where we saw a reported 11,637 people named ‘Caleb’. My birthyear, 2001, is the year just before the peak with a reported 11,171 namings.\n\n\nRead and format data\n#df = px.data.gapminder().query(\"country=='Canada'\")\n'''mark it with \nyear I was born, \nmin usage,\nmax usage'''\nchart = px.line(\n    df.query('name == \"Caleb\"'), \n    x=\"year\", \n    y=\"Total\",\n    color = \"name\", \n    title='Popularity of the name \"Caleb\"')\nchart.add_trace(go.Scatter(\n    x =[2001, 2002, 1956],\n    y = [11171, 11637, 5], \n    mode = \"markers\", \n    text = ['The year I was born', 'The year of highest popularity', 'The year of lowest popularity']))   \nchart.add_annotation(\n    x = 2001, \n    y = 11171,\n    text=\"The year I was born\",\n    showarrow=True,\n    arrowhead=1,\n    ax=-100,  \n    ay=70,\n    )                  \nchart.add_annotation(\n    x = 2002, \n    y = 11637,\n    text=\"The year of highest popularity\",\n    showarrow=True,\n    arrowhead=1,\n    ax=-130,  \n    ay=20,\n    )                  \nchart.update_layout(\n    plot_bgcolor = 'white',\n    xaxis_title = 'Year',\n    yaxis_title = 'Total', \n    title_x = 0.5,\n    title_font = dict(size = 20)\n)      \nchart.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - [What’s In a Name?]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nThe name ‘Brittney’ experienced it’s max usage in the year 1989. With this information, we would guess that her age is most likely 35. The years of least popularity on each side of the graph was 1974 and 2015, so we would say she is no older than 50, and no younger than 9.\n::: {#cell-Q2 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.line(\n    df.query('name == \"Brittney\"'), \n    x=\"year\", \n    y=\"Total\",\n    color = \"name\", \n    title='Usage of the name \"Brittney\"')\nchart.add_trace(go.Scatter(\n    x =[1989],\n    y = [7417.5], \n    mode = \"markers\", \n    text = []))               \nchart.update_layout(\n    plot_bgcolor = 'white',\n    xaxis_title = 'Year',\n    yaxis_title = 'Total', \n    title_x = 0.5,\n    title_font = dict(size = 20))\nchart.add_annotation(x = 1989, y = 7417.5,\n    text=\"The peak in popularity for 'Brittney'\")\nchart.show()\n\n\n                                                \n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - [What’s In a Name?]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nOf the four names, ‘Mary’ is by far the most popular, seeing a peak of 53,791 usages in the year 1950. Though it isn’t as popular, the names ‘Martha’ and ‘Mary’ see very similar trends with an increase in the 1910s and in the 1940s before peetering out to low popularity. ‘Peter’ and ‘Paul’ also have similar trends to each others, seeing a peak in the 50s and then bottoming out again. The only commonality between the four name is seeing a decline starting in the 80s and continuing that descent into 2015.\n::: {#cell-Q3 chart .cell execution_count=5}\n\nplot example\n# Include and execute your code here\n\nfig = px.line(\n    df.query('name == [\"Peter\", \"Paul\", \"Mary\", \"Martha\"]'), \n    x=\"year\", \n    y=\"Total\", \n    color='name',\n    title = 'Comparing the Popularity of the Names \"Peter\", \"Paul\", \"Martha\", and \"Mary\"')\nchart.update_layout(\n    plot_bgcolor = 'white',\n    xaxis_title = 'Year',\n    yaxis_title = 'Total', \n    title_x = 0.5,\n    title_font = dict(size = 20))\nfig.show()\n\n\n                                                \n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - [What’s In a Name?]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI chose the name Jordan, in reference to Michael Jordan from the blockbuster film ‘Space Jam’. I chose this name because not only did the movie have an effect, but even more noticably were the effect of his accomplishments outside of hollywood. The name had very low popularity up unitl the 1980s, seeing its lowpoint of 22 uses in 1951. Michael Jordan became relevent soon after the name’s popularity rise, starting his freshman season on University of North Carolina’s basketball team. But, it wasn’t until Michael Jordan’s rookie year in the NBA, 1984, where the name skyrocketed. Going from a name usage count of 2745 in 1984, to 11043 uses by 1990. Coincedentally, this is also year Michael Jordan won his first NBA championship. The name drops slightly over the years, but we see it another increase again following the release of his hit movie ‘Space Jam’ in 1996. The name once again hits it’s a peak in 1998, when Michael Jordan completed his second three-peat championship run. This was the same year that he retired from the Chicago Bulls, and the name never saw the same popularity again.\n::: {#cell-Q4 chart .cell execution_count=6}\n\nplot example\n# Include and execute your code here\nchart = px.line(\n    df.query('name == \"Jordan\"'), \n    x =\"year\", \n    y =\"Total\", \n    color = 'name',\n    title = \"The Impact of Space Jam and Michael Jordan's fame on the name 'Jordan'\")\n\nchart.add_trace(go.Scatter(\n    x =[1982, 1984, 1991, 1996, 1998],\n    y = [2195, 2745, 10785, 10074, 10760], \n    mode = \"markers\", \n    text = [\"Jordan's freshman year at UNC\", \n    \"Jordan's rookie NBA season\",\n    \"Jordan wins his first NBA championship\",\n    \"The release of Space Jam\",\n    \"Jordan  wins second championship 3-peat, announces retirement\",\n    ]))\nchart.add_annotation(x = 1996, y = 10074,\n    text=\"The release of Space Jam\",\n    showarrow=True,\n    arrowhead=1,\n    ax=10,  \n    ay=50,\n    )\nchart.add_annotation(x = 1950, y = 8000,\n    text=\"You may hover over the unmarkerd red dots to get more info \")\nchart.update_layout(\n    plot_bgcolor = 'white',\n    xaxis_title = 'Year',\n    yaxis_title = 'Total', \n    title_x = 0.5,\n    title_font = dict(size = 18))             \nchart.show()\n\n\n                                                \n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "",
    "text": "The mediocre playing quality of the Tampa Bay Rays is something very interesting to look at wiht what it tells about the MLB. Both of these teams are very young and due to the youth of their franchises, they have very limited money to spend compared to the more rooted baseball teams like the Yankees or the Dodgers. Because of this, other teams can always intice the better players because they can always outbid the poorer teams. If the MLB chanegd their format to include a salary cap, I believe this would reflect a drastic difference in how new franchises perform at the start of their life times becuase they always start at a playing field.\n\n\nRead and format project data\n# Include and execute your code here\nsqlite_file = r'C:\\Users\\caleb\\OneDrive\\Documents\\GitHub\\CPeterson-Portfolio\\lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "",
    "text": "The mediocre playing quality of the Tampa Bay Rays is something very interesting to look at wiht what it tells about the MLB. Both of these teams are very young and due to the youth of their franchises, they have very limited money to spend compared to the more rooted baseball teams like the Yankees or the Dodgers. Because of this, other teams can always intice the better players because they can always outbid the poorer teams. If the MLB chanegd their format to include a salary cap, I believe this would reflect a drastic difference in how new franchises perform at the start of their life times becuase they always start at a playing field.\n\n\nRead and format project data\n# Include and execute your code here\nsqlite_file = r'C:\\Users\\caleb\\OneDrive\\Documents\\GitHub\\CPeterson-Portfolio\\lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nRead and format data\n# Include and execute your code here\np = \"\"\"\n\nSELECT DISTINCT cp.playerID\n,      schoolID\n,      salary\n,      sa.yearID\n,      sa.teamID \nFROM collegeplaying AS cp\nLEFT JOIN salaries as sa\n    ON  cp.playerid = sa.playerid\nWHERE cp.schoolID = 'idbyuid'\nORDER BY salary DESC\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\n\n\n\n\n\n\nplayerID\nschoolID\nsalary\nyearID\nteamID\n\n\n\n\n0\nlindsma01\nidbyuid\n4000000.0\n2014.0\nCHA\n\n\n1\nlindsma01\nidbyuid\n3600000.0\n2012.0\nBAL\n\n\n2\nlindsma01\nidbyuid\n2800000.0\n2011.0\nCOL\n\n\n3\nlindsma01\nidbyuid\n2300000.0\n2013.0\nCHA\n\n\n4\nlindsma01\nidbyuid\n1625000.0\n2010.0\nHOU\n\n\n5\nstephga01\nidbyuid\n1025000.0\n2001.0\nSLN\n\n\n6\nstephga01\nidbyuid\n900000.0\n2002.0\nSLN\n\n\n7\nstephga01\nidbyuid\n800000.0\n2003.0\nSLN\n\n\n8\nstephga01\nidbyuid\n550000.0\n2000.0\nSLN\n\n\n9\nlindsma01\nidbyuid\n410000.0\n2009.0\nFLO\n\n\n10\nlindsma01\nidbyuid\n395000.0\n2008.0\nFLO\n\n\n11\nlindsma01\nidbyuid\n380000.0\n2007.0\nFLO\n\n\n12\nstephga01\nidbyuid\n215000.0\n1999.0\nSLN\n\n\n13\nstephga01\nidbyuid\n185000.0\n1998.0\nPHI\n\n\n14\nstephga01\nidbyuid\n150000.0\n1997.0\nPHI\n\n\n15\ncatetr01\nidbyuid\nNaN\nNaN\nNone",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWrite an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\np = \"\"\"\n\nSELECT playerID\n,      yearID\n,      H\n,      AB\n,      h*(1.0)/ab as 'ba'\nFROM batting\nWHERE ab &gt; 1 \nORDER BY r*(1.0)/ab DESC, playerid\nLIMIT 5\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nba\n\n\n\n\n0\nalexama01\n1980\n1\n3\n0.333333\n\n\n1\nhopkido01\n1975\n1\n6\n0.166667\n\n\n2\nburgmto01\n1968\n0\n2\n0.000000\n\n\n3\njimerch01\n2007\n2\n2\n1.000000\n\n\n4\nnoelri01\n2015\n1\n2\n0.500000",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nUse the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n\n\nRead and format data\n# Include and execute your code here\np = \"\"\"\n\nSELECT playerID\n,      yearID\n,      H\n,      AB\n,      h*(1.0)/ab as 'ba'\nFROM batting\nWHERE ab &gt; 10\nORDER BY ba DESC, playerid\nLIMIT 5\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nba\n\n\n\n\n0\nnymanny01\n1974\n9\n14\n0.642857\n\n\n1\ncarsoma01\n2013\n7\n11\n0.636364\n\n\n2\nsilvech01\n1948\n8\n14\n0.571429\n\n\n3\npuccige01\n1930\n9\n16\n0.562500\n\n\n4\napplepe01\n1927\n6\n11\n0.545455",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-4",
    "href": "Projects/project3.html#questiontask-4",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nNow calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n\n\nRead and format data\n# Include and execute your code here\np = \"\"\"\n\nSELECT playerID\n,      SUM(H) as 'total hits'\n,      SUM(AB) as 'total at bats'\n,      SUM(H)*(1.0)/SUM(AB) as 'ba'\nFROM batting\nWHERE AB &gt; 100\nGROUP BY playerID\nORDER BY ba DESC, playerID\nLIMIT 5\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\n\n\n\n\n\n\nplayerID\ntotal hits\ntotal at bats\nba\n\n\n\n\n0\nhazlebo01\n54\n134\n0.402985\n\n\n1\ndaviscu01\n40\n105\n0.380952\n\n\n2\nfishesh01\n95\n254\n0.374016\n\n\n3\nwoltery01\n51\n138\n0.369565\n\n\n4\ncobbty01\n4189\n11436\n0.366299",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-5",
    "href": "Projects/project3.html#questiontask-5",
    "title": "Client Report - [Finding Relationships in Baseball]",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\nThe Tampa Bay Rays and the Arizona Diamondbacks were the two expansion teams of 1998. This chart shows the Win-Loss ratio of the two teams over the course of their MLB carers. The Rays started off much worse than the Diamondbacks. Over time, the both seemed to produce fairly average play with the occasional successful positive season. As of the last few years though, both teams seem to be on a steep positive trend for success.\n\n\nRead and format data\n# Include and execute your code here\np = \"\"\"\n\nSELECT yearID\n,      name\n,      W\n,      L\n,      ((W*1.0)/162) as 'Win-Loss Ratio',\n  CASE\n      WHEN name = 'Tampa Bay Rays' THEN 'Tampa Bay Rays'\n      WHEN name = 'Tampa Bay Devil Rays' Then 'Tampa Bay Rays'\n      ELSE name\n      END AS true_name\n  FROM teams\n  \nWHERE true_name LIKE 'Tampa Bay%' OR name LIKE 'Arizona%'\n\n\"\"\"\n\npd.read_sql_query(p, con)\n\n\n\n\n\n\n\n\n\nyearID\nname\nW\nL\nWin-Loss Ratio\ntrue_name\n\n\n\n\n0\n1998\nArizona Diamondbacks\n65\n97\n0.401235\nArizona Diamondbacks\n\n\n1\n1998\nTampa Bay Devil Rays\n63\n99\n0.388889\nTampa Bay Rays\n\n\n2\n1999\nArizona Diamondbacks\n100\n62\n0.617284\nArizona Diamondbacks\n\n\n3\n1999\nTampa Bay Devil Rays\n69\n93\n0.425926\nTampa Bay Rays\n\n\n4\n2000\nArizona Diamondbacks\n85\n77\n0.524691\nArizona Diamondbacks\n\n\n5\n2000\nTampa Bay Devil Rays\n69\n92\n0.425926\nTampa Bay Rays\n\n\n6\n2001\nArizona Diamondbacks\n92\n70\n0.567901\nArizona Diamondbacks\n\n\n7\n2001\nTampa Bay Devil Rays\n62\n100\n0.382716\nTampa Bay Rays\n\n\n8\n2002\nArizona Diamondbacks\n98\n64\n0.604938\nArizona Diamondbacks\n\n\n9\n2002\nTampa Bay Devil Rays\n55\n106\n0.339506\nTampa Bay Rays\n\n\n10\n2003\nArizona Diamondbacks\n84\n78\n0.518519\nArizona Diamondbacks\n\n\n11\n2003\nTampa Bay Devil Rays\n63\n99\n0.388889\nTampa Bay Rays\n\n\n12\n2004\nArizona Diamondbacks\n51\n111\n0.314815\nArizona Diamondbacks\n\n\n13\n2004\nTampa Bay Devil Rays\n70\n91\n0.432099\nTampa Bay Rays\n\n\n14\n2005\nArizona Diamondbacks\n77\n85\n0.475309\nArizona Diamondbacks\n\n\n15\n2005\nTampa Bay Devil Rays\n67\n95\n0.413580\nTampa Bay Rays\n\n\n16\n2006\nArizona Diamondbacks\n76\n86\n0.469136\nArizona Diamondbacks\n\n\n17\n2006\nTampa Bay Devil Rays\n61\n101\n0.376543\nTampa Bay Rays\n\n\n18\n2007\nArizona Diamondbacks\n90\n72\n0.555556\nArizona Diamondbacks\n\n\n19\n2007\nTampa Bay Devil Rays\n66\n96\n0.407407\nTampa Bay Rays\n\n\n20\n2008\nArizona Diamondbacks\n82\n80\n0.506173\nArizona Diamondbacks\n\n\n21\n2008\nTampa Bay Rays\n97\n65\n0.598765\nTampa Bay Rays\n\n\n22\n2009\nArizona Diamondbacks\n70\n92\n0.432099\nArizona Diamondbacks\n\n\n23\n2009\nTampa Bay Rays\n84\n78\n0.518519\nTampa Bay Rays\n\n\n24\n2010\nArizona Diamondbacks\n65\n97\n0.401235\nArizona Diamondbacks\n\n\n25\n2010\nTampa Bay Rays\n96\n66\n0.592593\nTampa Bay Rays\n\n\n26\n2011\nArizona Diamondbacks\n94\n68\n0.580247\nArizona Diamondbacks\n\n\n27\n2011\nTampa Bay Rays\n91\n71\n0.561728\nTampa Bay Rays\n\n\n28\n2012\nArizona Diamondbacks\n81\n81\n0.500000\nArizona Diamondbacks\n\n\n29\n2012\nTampa Bay Rays\n90\n72\n0.555556\nTampa Bay Rays\n\n\n30\n2013\nArizona Diamondbacks\n81\n81\n0.500000\nArizona Diamondbacks\n\n\n31\n2013\nTampa Bay Rays\n92\n71\n0.567901\nTampa Bay Rays\n\n\n32\n2014\nArizona Diamondbacks\n64\n98\n0.395062\nArizona Diamondbacks\n\n\n33\n2014\nTampa Bay Rays\n77\n85\n0.475309\nTampa Bay Rays\n\n\n34\n2015\nArizona Diamondbacks\n79\n83\n0.487654\nArizona Diamondbacks\n\n\n35\n2015\nTampa Bay Rays\n80\n82\n0.493827\nTampa Bay Rays\n\n\n36\n2016\nArizona Diamondbacks\n69\n93\n0.425926\nArizona Diamondbacks\n\n\n37\n2016\nTampa Bay Rays\n68\n94\n0.419753\nTampa Bay Rays\n\n\n38\n2017\nArizona Diamondbacks\n93\n69\n0.574074\nArizona Diamondbacks\n\n\n39\n2017\nTampa Bay Rays\n80\n82\n0.493827\nTampa Bay Rays\n\n\n40\n2018\nArizona Diamondbacks\n82\n80\n0.506173\nArizona Diamondbacks\n\n\n41\n2018\nTampa Bay Rays\n90\n72\n0.555556\nTampa Bay Rays\n\n\n42\n2019\nArizona Diamondbacks\n85\n77\n0.524691\nArizona Diamondbacks\n\n\n43\n2019\nTampa Bay Rays\n96\n66\n0.592593\nTampa Bay Rays\n\n\n\n\n\n\n\n::: {#cell-Q5 chart .cell execution_count=8}\n\nplot example\nchart = px.line(\n    pd.read_sql_query(p, con).query('true_name == [\"Tampa Bay Rays\", \"Arizona Diamondbacks\"]'), \n    x =\"yearID\", \n    y =\"Win-Loss Ratio\", \n    color = 'true_name',\n    title = \"The Success of the Tampa Bay Rays vs the Arizona Diamondbacks\",\n    )\n\nchart.update_layout(\n    plot_bgcolor = 'white',\n    xaxis_title = 'Year',\n    yaxis_title = 'Win-Loss Ratio', \n    title_x = 0.5,\n    title_font = dict(size = 20)\n)\n\n\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#elevator-pitch",
    "href": "Projects/project5.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-1",
    "href": "Projects/project5.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-2",
    "href": "Projects/project5.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-3",
    "href": "Projects/project5.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Caleb Peterson’s CV",
    "section": "",
    "text": "pet22063@byui.edu | (727) 505-0536\n\n\n\n2nd Year Student at Brigham Young University - Idaho\n\n\n\n2015-2019 Etowah High School, Woodstock\nJanuary 2023 - now Brigham Young University - Idaho, Rexburg\n\n\n\n2019 Brand Associate, Banana Republic Factory Store\n2020 Volunteer Missionary, The Church of Jesus Christ of Latter-Day Saints\n2023 Warehouse Laborer, Admiral Beverage Corporation"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Caleb Peterson’s CV",
    "section": "",
    "text": "2nd Year Student at Brigham Young University - Idaho"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Caleb Peterson’s CV",
    "section": "",
    "text": "2015-2019 Etowah High School, Woodstock\nJanuary 2023 - now Brigham Young University - Idaho, Rexburg"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Caleb Peterson’s CV",
    "section": "",
    "text": "2019 Brand Associate, Banana Republic Factory Store\n2020 Volunteer Missionary, The Church of Jesus Christ of Latter-Day Saints\n2023 Warehouse Laborer, Admiral Beverage Corporation"
  }
]